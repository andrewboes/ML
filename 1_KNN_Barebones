import numpy as np
import time
import math
import timeit

starttime = timeit.default_timer()
    
def main():
    
    print("Start")
    print(timeit.default_timer() - starttime)
    # assert_get_nearest_neighbors()
    # assert_predict()
    # assert_compute_accuracy()


    train_X, train_y, test_X = load_data()
    
    print("Data Loaded")
    print(timeit.default_timer() - starttime)
    
    
    search_k(train_X, train_y, attWt, 4, [3,5,7,9])
    
    # best_k = 9
    
    # # Make predictions on test set
    # pred_test_y = predict(train_X, train_y, test_X, best_k)    
    
    # # add index and header then save to file
    # test_out = np.concatenate((np.expand_dims(np.array(range(2000),dtype=np.int), axis=1), pred_test_y), axis=1)
    # header = np.array([["id", "income"]])
    # test_out = np.concatenate((header, test_out))
    # np.savetxt('test_predicted.csv', test_out, fmt='%s', delimiter=',')
   
    return
    
def get_nearest_neighbors(example_set, query, k):      
    
    #calculate norm for example set - query, axis for broadcasting
    dist = np.linalg.norm(example_set-query, axis=1)
    
    # set k = full set if it is set too high when playing with data
    if k > (len(example_set)-1):
        k = (len(example_set)-1)
        
    # return k length subset
    ret = np.sort(np.argpartition(dist, k)[:k])
    return ret

def predict(examples_X, examples_y, queries_X, k, attWt): 
    
    w_examples_X = examples_X * attWt
    w_queries_X = queries_X * attWt
    
    # For each query, run a knn classifier
    predicted_y = [knn_classify_point(w_examples_X, examples_y, query, k, attWt) for query in w_queries_X]

    return np.array(predicted_y,dtype=np.int)[:,np.newaxis]

def knn_classify_point(examples_X, examples_y, query, k, attWt):
    
    # get the value of examples_y on the indices returned from get_nearest_neighbors
    nn = examples_y[get_nearest_neighbors(examples_X, query, k)]
    
    #get average of k nearest neighors, round to nearest int (0 or 1)
    ret = int(round(np.average(nn)))
    return ret

def cross_validation(train_X, train_y, num_folds, k, attWt):
    
    # the number of rows in each segment
    seg = int(round(len(train_y)//num_folds))
    
    i = 0
    seg_start = (i*seg)
    seg_end = (i+1)*seg
    
    accuracy_results = np.empty(num_folds, dtype=float) 
    
    for i in range(num_folds):
        results_pred = predict(
            np.concatenate((train_X[0:seg_start],train_X[seg_end:len(train_X)]), axis=0), 
            np.concatenate((train_y[0:seg_start],train_y[seg_end:len(train_y)]), axis=0), 
            train_X[seg_start:(i+1)*seg_end], k, attWt)
        results_true = train_y[seg_start:(i+1)*seg_end]
        accuracy_results[i] = compute_accuracy(results_true, results_pred)
        # print(str(i+1)+"/"+str(num_folds))   
        # print(timeit.default_timer() - starttime)
            
    return np.average(accuracy_results), np.var(accuracy_results)

def compute_accuracy(true_y, predicted_y):
    accuracy = np.mean(true_y == predicted_y)
    return accuracy

def load_data():
    traindata = np.genfromtxt('train_small.csv', delimiter=',')[1:, 1:]
    # traindata = np.genfromtxt('train_med.csv', delimiter=',')[1:, 1:]
    # traindata = np.genfromtxt('train.csv', delimiter=',')[1:, 1:]
    # traindata = np.genfromtxt('train.csv', delimiter=',')[1:, :] #include IDs
    train_X = traindata[:, :-1]
    train_y = traindata[:, -1]
    train_y = train_y[:, np.newaxis]

    test_X = np.genfromtxt('test_pub.csv', delimiter=',')[1:, 1:]

    return train_X, train_y, test_X

def assert_get_nearest_neighbors():
    
    example_train_x = np.array([[1, 0, 2], [3, -2, 4], [5, -2, 4], [4, 2, 1.5], [3.2, np.pi, 2], [-5, 0, 1]])
    example_train_y = np.array([[0], [1], [1], [1], [0], [1]])

    #########
    # Sanity Check 1: If I query with examples from the training set 
    # and k=1, each point should be its own nearest neighbor
    for i in range(len(example_train_x)):
        assert(i == get_nearest_neighbors(
            example_train_x, example_train_x[i], 1))

    #########
    # Sanity Check 2: See if neighbors are right for some examples (ignoring order)
    nn_idx = get_nearest_neighbors(example_train_x, np.array( [ 1, 4, 2] ), 2)
    assert(set(nn_idx).difference(set([4,3]))==set())

    nn_idx = get_nearest_neighbors(example_train_x, np.array( [ 1, -4, 2] ), 3)
    assert(set(nn_idx).difference(set([1,0,2]))==set())

    nn_idx = get_nearest_neighbors(example_train_x, np.array( [ 10, 40, 20] ), 5)
    assert(set(nn_idx).difference(set([4, 3, 0, 2, 1]))==set())
    
    #########
    # Sanity Check 3: Neighbors for increasing k should be subsets
    query = np.array( [ 10, 40, 20] )
    p_nn_idx = get_nearest_neighbors(example_train_x, query, 1)
    for k in range(2,7):
      nn_idx = get_nearest_neighbors(example_train_x, query, k)
      assert(set(p_nn_idx).issubset(nn_idx))
      p_nn_idx = nn_idx
    
    return

def assert_predict():
    
    example_train_x = np.array([[1, 0, 2], [3, -2, 4], [5, -2, 4], [4, 2, 1.5], [3.2, np.pi, 2], [-5, 0, 1]])
    example_train_y = np.array([[0], [1], [1], [1], [0], [1]])

    #########
    # Test out our prediction code
    queries = np.array( [[ 10, 40, 20], [-2, 0, 5], [0,0,0]] )
    pred = predict(example_train_x, example_train_y, queries, 3)
    assert( np.all(pred == np.array([[0],[1],[0]])))
    
    return

def assert_compute_accuracy():
    
    #########
    # Test our our accuracy code
    true_y = np.array([[0],[1],[2],[1],[1],[0]])
    pred_y = np.array([[5],[1],[0],[0],[1],[0]])                    
    assert( compute_accuracy(true_y, pred_y) == 3/6)

    pred_y = np.array([[5],[1],[2],[0],[1],[0]])                    
    assert( compute_accuracy(true_y, pred_y) == 4/6)
    
    return

def search_k(train_X, train_y, attWt, folds, k_values):
    
    print("performing " + str(folds) + "-fold cross validation")
    for k in k_values:
        t0 = time.time()


        acc = predict(train_X, train_y, train_X, k, attWt)
        train_acc = compute_accuracy(train_y, acc)
            
        val_acc, val_acc_var = cross_validation(train_X, train_y, folds, k, attWt)
        
        t1 = time.time()
        print("k = {:5d} -- train acc = {:.2f}%  val acc = {:.2f}% ({:.4f})\t\t[exe_time = {:.2f}]".format(k, train_acc*100, val_acc*100, val_acc_var*100, t1-t0))
    
    return



if __name__ == "__main__":
    main()
