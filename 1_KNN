import numpy as np
import time
import math
import timeit
import random

starttime = timeit.default_timer()
    
def main():
    
    print("Start")
    print(timeit.default_timer() - starttime)
    # assert_get_nearest_neighbors()
    # assert_predict()
    # assert_compute_accuracy()


    train_X, train_y, test_X = load_data()
    
    print("Data Loaded")
    print(timeit.default_timer() - starttime)
    
    
    # declare an array to hold attribute weight - vector the same width as data
    # 1 = normal weight, 0.5 = half, 2.0 = double etc
    attWt = np.ones(test_X.shape[1], dtype=float) 
    
    
    # ---------- search k ----------
    # search_k(train_X, train_y, attWt, 4, [9])
    # /--------- search k ----------
    
    # -------- search weight --------
    # list of results
    # cnt = 0;
    # ret = 1
    
    # while (ret == 1):
    #     cnt = cnt + 1
    #     weightresults = []
    #     ret = 0
    #     usedWeights = []
    #     rand = random.randrange(0,len(attWt))
        
    #     for a in range(len(attWt)):
            
    #         while rand in usedWeights:
    #            rand = random.randrange(0,len(attWt))
               
    #         usedWeights.append(rand)
            
    #         res = search_weight_mult(train_X, train_y, attWt, 4, 9, rand, [1, 0.001, 0.1, 0.5, 2, 10, 1000], weightresults)
    #         if res == 1:
    #             ret = 1
        
    #     weightresults.sort()
        
    #     # save weight results to file for easier analysis
    #     weight_header = np.array([["attribute index", "attribute weight value", "accuracy", "variance"]])
    #     test_out = np.concatenate((weight_header, weightresults))
    #     np.savetxt('weight_search_' + str(cnt) + '.csv', test_out, fmt='%s', delimiter=',')
    
    # /------- search weight --------

   
    # -------- set hyper paramters --------

    best_k = 9
    
    # avg of 5 tie values
    # best_attWt = [10, 0.5, 5, 10, 0.1, 1, 1, 1, 1, 1, 2, 1, 0.1, 2, 0.3, 5, 0.1, 0.1, 0.3, 1, 5, 2, 7.5, 7.5, 2, 1, 2, 1.05, 1, 0.5, 1, 1, 7.5, 0.1, 0.1, 0.1, 5, 7.5, 0.4, 0.5, 0.1, 0.1, 0.3, 0.1, 2, 7.5, 1, 7.5, 0.5, 5, 0.3, 0.3, 0.3, 5, 0.1, 7.5, 5, 0.3, 5, 1, 1, 5, 0.5, 0.3, 2, 0.5, 2, 1, 0.5, 1, 7.5, 0.3, 0.3, 0.3, 2, 2, 1, 5, 2, 5, 0.3, 2, 0.2, 0.3, 0.1]

    #ties = 1
    # best_attWt = [10, 0.5, 5, 10, 0.1, 1, 1, 1, 1, 1, 2, 1, 0.1, 2, 0.3, 5, 0.1, 0.1, 0.3, 1, 5, 2, 1, 1, 2, 1, 2, 1, 1, 0.5, 1, 1, 1, 0.1, 0.1, 0.1, 5, 1, 1, 0.5, 0.1, 0.1, 0.3, 0.1, 2, 1, 1, 1, 0.5, 5, 1, 0.3, 1, 5, 0.1, 1, 5, 1, 5, 1, 1, 5, 0.5, 1, 2, 0.5, 2, 1, 0.5, 1, 1, 1, 1, 0.3, 2, 2, 1, 5, 2, 5, 1, 2, 1, 1, 0.1]

    # 84.63% (0.0036)
    # best_attWt = [10, 1, 5, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    # 84.37% (0.0050)	
    # best_attWt = [10, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    # 84.65% (0.0076)	
    # best_attWt = [1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    # 84.94% (0.0065)		
    # best_attWt = [1, 1, 5, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    #83.49% (0.0091)	
    # best_attWt = [100, 1, 5, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    # results from mult [0:4]	 86.51% (0.0067)
    # best_attWt = [10, 3, 1000000, 0.000006, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    # results from mult [4:0]	 87.15% (0.0037)	
    # best_attWt = [1, 1, 30000, 50000, 0.0009, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

    # results from mult rand	 87.65% (0.0012)	
    best_attWt = [1,1,20000,1000,0.00005,1,1,1,1,1,1,1,1,0.001,0.001,0.001,0.1,1,1,1,2,1,1,10,1,1,200,0.001,1,1,1,1,1,1,1,1,2,0.5,2,0.001,0.001,0.0000001,1,0.5,1,2,0.001,10,0.001,10,1,1,1,1,1,1,1,1,1,1,1,0.001,1,1,2,1,1,1,2,2,1,1,0.005,1,0.001,0.001,1,0.5,1,0.001,1,20,0.001,1,1]

    # /------- set hyper paramters --------
    
    
    # ------- generate prediction -------
    
    # Make predictions on test set
    pred_test_y = predict(train_X, train_y, test_X, best_k, best_attWt)    
    
    # add index and header then save to file
    test_out = np.concatenate((np.expand_dims(np.array(range(2000),dtype=np.int), axis=1), pred_test_y), axis=1)
    header = np.array([["id", "income"]])
    test_out = np.concatenate((header, test_out))
    np.savetxt('test_predicted.csv', test_out, fmt='%s', delimiter=',')
    # /------ generate prediction -------
   
    return
    
def get_nearest_neighbors(example_set, query, k):      
    
    
    #calculate norm for example set - query, axis for broadcasting
    dist = np.linalg.norm(example_set-query, axis=1)
    
    
    # set k = full set if it is set too high when playing with data
    if k > (len(example_set)-1):
        k = (len(example_set)-1)
        
    # return k length subset
    ret = np.sort(np.argpartition(dist, k)[:k])
    return ret

def predict(examples_X, examples_y, queries_X, k, attWt): 
    
    w_examples_X = examples_X * attWt
    w_queries_X = queries_X * attWt
    
    # For each query, run a knn classifier
    predicted_y = [knn_classify_point(w_examples_X, examples_y, query, k) for query in w_queries_X]

    return np.array(predicted_y,dtype=np.int)[:,np.newaxis]

def knn_classify_point(examples_X, examples_y, query, k):
    
    # get the value of examples_y on the indices returned from get_nearest_neighbors
    nn = examples_y[get_nearest_neighbors(examples_X, query, k)]
    
    #get average of k nearest neighbors, round to nearest int (0 or 1)
    ret = int(round(np.average(nn)))
    return ret

def cross_validation(train_X, train_y, num_folds, k, attWt):
    
    i = 0
    
    # the range of rows in each segment
    seg_start = (i*int(round(len(train_y)//num_folds)))
    seg_end = (i+1)*int(round(len(train_y)//num_folds))
    
    accuracy_results = np.empty(num_folds, dtype=float) 
    
    for i in range(num_folds):
        results_pred = predict(
            np.concatenate((train_X[0:seg_start],train_X[seg_end:len(train_X)]), axis=0), 
            np.concatenate((train_y[0:seg_start],train_y[seg_end:len(train_y)]), axis=0), 
            train_X[seg_start:(i+1)*seg_end], k, attWt)
        results_true = train_y[seg_start:(i+1)*seg_end]
        accuracy_results[i] = compute_accuracy(results_true, results_pred)
            
    return np.average(accuracy_results), np.var(accuracy_results)

def compute_accuracy(true_y, predicted_y):
    accuracy = np.mean(true_y == predicted_y)
    return accuracy

def load_data():
    # traindata = np.genfromtxt('train_small.csv', delimiter=',')[1:, 1:]
    # traindata = np.genfromtxt('train_med.csv', delimiter=',')[1:, 1:]
    traindata = np.genfromtxt('train.csv', delimiter=',')[1:, 1:]
    # traindata = np.genfromtxt('train.csv', delimiter=',')[1:, :] #include IDs
    train_X = traindata[:, :-1]
    train_y = traindata[:, -1]
    train_y = train_y[:, np.newaxis]

    test_X = np.genfromtxt('test_pub.csv', delimiter=',')[1:, 1:]

    return train_X, train_y, test_X

def assert_get_nearest_neighbors():
    
    example_train_x = np.array([[1, 0, 2], [3, -2, 4], [5, -2, 4], [4, 2, 1.5], [3.2, np.pi, 2], [-5, 0, 1]])
    example_train_y = np.array([[0], [1], [1], [1], [0], [1]])

    #########
    # Sanity Check 1: If I query with examples from the training set 
    # and k=1, each point should be its own nearest neighbor
    for i in range(len(example_train_x)):
        assert(i == get_nearest_neighbors(
            example_train_x, example_train_x[i], 1))

    #########
    # Sanity Check 2: See if neighbors are right for some examples (ignoring order)
    nn_idx = get_nearest_neighbors(example_train_x, np.array( [ 1, 4, 2] ), 2)
    assert(set(nn_idx).difference(set([4,3]))==set())

    nn_idx = get_nearest_neighbors(example_train_x, np.array( [ 1, -4, 2] ), 3)
    assert(set(nn_idx).difference(set([1,0,2]))==set())

    nn_idx = get_nearest_neighbors(example_train_x, np.array( [ 10, 40, 20] ), 5)
    assert(set(nn_idx).difference(set([4, 3, 0, 2, 1]))==set())
    
    #########
    # Sanity Check 3: Neighbors for increasing k should be subsets
    query = np.array( [ 10, 40, 20] )
    p_nn_idx = get_nearest_neighbors(example_train_x, query, 1)
    for k in range(2,7):
      nn_idx = get_nearest_neighbors(example_train_x, query, k)
      assert(set(p_nn_idx).issubset(nn_idx))
      p_nn_idx = nn_idx
    
    return

def assert_predict():
    
    example_train_x = np.array([[1, 0, 2], [3, -2, 4], [5, -2, 4], [4, 2, 1.5], [3.2, np.pi, 2], [-5, 0, 1]])
    example_train_y = np.array([[0], [1], [1], [1], [0], [1]])

    #########
    # Test out our prediction code
    queries = np.array( [[ 10, 40, 20], [-2, 0, 5], [0,0,0]] )
    pred = predict(example_train_x, example_train_y, queries, 3)
    assert( np.all(pred == np.array([[0],[1],[0]])))
    
    return

def assert_compute_accuracy():
    
    #########
    # Test our our accuracy code
    true_y = np.array([[0],[1],[2],[1],[1],[0]])
    pred_y = np.array([[5],[1],[0],[0],[1],[0]])                    
    assert( compute_accuracy(true_y, pred_y) == 3/6)

    pred_y = np.array([[5],[1],[2],[0],[1],[0]])                    
    assert( compute_accuracy(true_y, pred_y) == 4/6)
    
    return

def search_k(train_X, train_y, attWt, folds, k_values):
    
    print("performing " + str(folds) + "-fold cross validation")
    for k in k_values:
        t0 = time.time()


        acc = predict(train_X, train_y, train_X, k, attWt)
        train_acc = compute_accuracy(train_y, acc)
            
        val_acc, val_acc_var = cross_validation(train_X, train_y, folds, k, attWt)
        
        t1 = time.time()
        print("k = {:5d} -- train acc = {:.2f}%  val acc = {:.2f}% ({:.4f})\t\t[exe_time = {:.2f}]".format(k, train_acc*100, val_acc*100, val_acc_var*100, t1-t0))
    
    return

def search_weight(train_X, train_y, attWt, folds, k, attIndex, att_values, weightResults):
    
    print("performing " + str(folds) + "-fold cross validation, k="+str(k) + ", for attribute index:" + str(attIndex))

    for a in att_values:
        t0 = time.time()
        
        attWt[attIndex] = a

        acc = predict(train_X, train_y, train_X, k, attWt)
        train_acc = compute_accuracy(train_y, acc)
            
        val_acc, val_acc_var = cross_validation(train_X, train_y, folds, k, attWt)
        
        t1 = time.time()
        print("wt value = {:2f} -- train acc = {:.2f}%  val acc = {:.2f}% ({:.4f})\t\t[exe_time = {:.2f}]".format(a, train_acc*100, val_acc*100, val_acc_var*100, t1-t0))
                    
        weightResults.append([k,folds, attIndex, a, val_acc, val_acc_var]);
        attWt[attIndex] = 1
        
    return 

def search_weight_mult(train_X, train_y, attWt, folds, k, attIndex, att_values, weightResults):
    
    print("performing " + str(folds) + "-fold cross validation, k="+str(k) + ", for attribute index:" + str(attIndex))
    
    best_att_value = 0
    best_att_acc = 0
    best_att_var = 0
    changed = 0

    for a in att_values:
        t0 = time.time()
        
        attWt[attIndex] = attWt[attIndex] * a

        acc = predict(train_X, train_y, train_X, k, attWt)
        train_acc = compute_accuracy(train_y, acc)
            
        val_acc, val_acc_var = cross_validation(train_X, train_y, folds, k, attWt)
        
        t1 = time.time()
        print("wt value = {:2f} -- train acc = {:.2f}%  val acc = {:.2f}% ({:.4f})\t\t[exe_time = {:.2f}]".format(a, train_acc*100, val_acc*100, val_acc_var*100, t1-t0))
                    
        
        if val_acc > best_att_acc:
            best_att_value = attWt[attIndex]
            best_att_acc = val_acc
            best_att_var = val_acc_var
            if a != 1:
                changed = 1
        else:
            attWt[attIndex] = best_att_value
        
    weightResults.append([attIndex, best_att_value, best_att_acc, best_att_var]);
    return changed


if __name__ == "__main__":
    main()
